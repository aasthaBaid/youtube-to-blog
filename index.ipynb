{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b04ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aasthabaid/Documents/2025/projects/agentic_ai/yt_to_blog/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, List\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, END\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3227ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        youtube_url: The URL of the YouTube video to process.\n",
    "        transcript: The fetched transcript of the video.\n",
    "        title: The generated blog post title.\n",
    "        blog_post: The final generated blog content.\n",
    "        error: A field to store any error messages that occur.\n",
    "    \"\"\"\n",
    "    youtube_url: str\n",
    "    transcript: str\n",
    "    title: str\n",
    "    blog_post: str\n",
    "    error: str\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2900c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Fetches the transcript for a given YouTube URL.\n",
    "\n",
    "    Args:\n",
    "        state: The current state of the graph.\n",
    "\n",
    "    Returns:\n",
    "        An updated state with the transcript or an error message.\n",
    "    \"\"\"\n",
    "    print(\"--- 1. FETCHING TRANSCRIPT ---\")\n",
    "    try:\n",
    "        url = state.get(\"youtube_url\", \"\").strip()\n",
    "        if not url:\n",
    "            raise ValueError(\"YouTube URL is missing.\")\n",
    "            \n",
    "        loader = YoutubeLoader.from_youtube_url(url, add_video_info=False)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        if not documents:\n",
    "            return {\"error\": \"Could not retrieve transcript. The video may not have one available.\"}\n",
    "\n",
    "        # Combine the content of all document chunks into a single string\n",
    "        transcript_text = \" \".join([doc.page_content for doc in documents]).strip()\n",
    "        \n",
    "        print(f\"Transcript fetched successfully. Length: {len(transcript_text)} characters.\")\n",
    "        return {\"transcript\": transcript_text, \"error\": None}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR fetching transcript: {e}\")\n",
    "        return {\"error\": f\"Failed to fetch transcript: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e7d4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_title(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Generates a catchy, SEO-friendly title based on the transcript.\n",
    "\n",
    "    Args:\n",
    "        state: The current state of the graph.\n",
    "\n",
    "    Returns:\n",
    "        An updated state with the generated title or an error.\n",
    "    \"\"\"\n",
    "    print(\"--- 2. GENERATING BLOG TITLE ---\")\n",
    "    if state.get(\"error\"): # If there was an error in the previous step, skip this one\n",
    "        return {}\n",
    "        \n",
    "    transcript = state.get(\"transcript\", \"\")\n",
    "    \n",
    "    # Prompt template to guide the LLM\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"Based on the following video transcript, please generate a concise, engaging, and SEO-friendly title for a blog post.\n",
    "\n",
    "Transcript:\n",
    "\"{transcript}\"\n",
    "\n",
    "Title:\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create the generation chain\n",
    "    title_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    try:\n",
    "        title = title_chain.invoke({\"transcript\": transcript})\n",
    "        print(f\"Generated Title: {title}\")\n",
    "        return {\"title\": title, \"error\": None}\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR generating title: {e}\")\n",
    "        return {\"error\": f\"Failed to generate title: {e}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f367e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blog_post(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Generates the full blog post content using the title and transcript.\n",
    "\n",
    "    Args:\n",
    "        state: The current state of the graph.\n",
    "\n",
    "    Returns:\n",
    "        An updated state with the final blog post or an error.\n",
    "    \"\"\"\n",
    "    print(\"--- 3. GENERATING BLOG POST ---\")\n",
    "    if state.get(\"error\"):\n",
    "        return {}\n",
    "        \n",
    "    title = state.get(\"title\", \"\")\n",
    "    transcript = state.get(\"transcript\", \"\")\n",
    "    \n",
    "    # Prompt template for the final blog post\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are an expert blog post writer. Your task is to write a comprehensive, well-structured blog post using the provided title and video transcript.\n",
    "\n",
    "        **Blog Post Title:** {title}\n",
    "\n",
    "        **Video Transcript:**\n",
    "        {transcript}\n",
    "\n",
    "        ---\n",
    "        Instructions:\n",
    "        - Start with an engaging introduction that hooks the reader.\n",
    "        - Structure the content logically with clear headings and subheadings (using Markdown for formatting).\n",
    "        - Convert the key points from the transcript into well-written paragraphs.\n",
    "        - Maintain a consistent and informative tone.\n",
    "        - Conclude with a summary and a call to action if appropriate.\n",
    "        - Ensure the final output is only the blog post content itself.\n",
    "\n",
    "        **Final Blog Post:**\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create the generation chain\n",
    "    blog_post_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    try:\n",
    "        blog_post = blog_post_chain.invoke({\"title\": title, \"transcript\": transcript})\n",
    "        print(\"--- BLOG POST GENERATED ---\")\n",
    "        return {\"blog_post\": blog_post, \"error\": None}\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR generating blog post: {e}\")\n",
    "        return {\"error\": f\"Failed to generate blog post: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5159bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_error(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    A conditional edge function. It decides the next step based on\n",
    "    whether an error has occurred in the graph's state.\n",
    "    \"\"\"\n",
    "    if state.get(\"error\"):\n",
    "        print(\"--- An error occurred. Ending execution. ---\")\n",
    "        return \"end\" # An error occurred, terminate the graph\n",
    "    return \"continue\" # No error, proceed to the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7663c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"get_transcript\", get_transcript)\n",
    "workflow.add_node(\"generate_title\", generate_title)\n",
    "workflow.add_node(\"generate_blog_post\", generate_blog_post)\n",
    "\n",
    "# Define the edges and control flow\n",
    "workflow.set_entry_point(\"get_transcript\")\n",
    "\n",
    "# Conditional edge from get_transcript\n",
    "workflow.add_conditional_edges(\n",
    "    \"get_transcript\",\n",
    "    handle_error,\n",
    "    {\n",
    "        \"continue\": \"generate_title\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Conditional edge from generate_title\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_title\",\n",
    "    handle_error,\n",
    "    {\n",
    "        \"continue\": \"generate_blog_post\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# The final step before ending the graph\n",
    "workflow.add_edge(\"generate_blog_post\", END)\n",
    "\n",
    "# Compile the graph into a runnable application\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "998a646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. FETCHING TRANSCRIPT ---\n",
      "Transcript fetched successfully. Length: 134190 characters.\n",
      "--- 2. GENERATING BLOG TITLE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR generating title: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "--- An error occurred. Ending execution. ---\n",
      "\n",
      "==================================================\n",
      "Process finished with an error:\n",
      "Failed to generate title: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.youtube.com/watch?v=dIb-DujRNEo&t=5829s\"\n",
    "initial_state = {\"youtube_url\": url}\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if final_state.get(\"error\"):\n",
    "    print(\"Process finished with an error:\")\n",
    "    print(final_state[\"error\"])\n",
    "else:\n",
    "    print(\"Final Blog Post:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"# \" + final_state.get(\"title\", \"No Title Generated\"))\n",
    "    print(final_state.get(\"blog_post\", \"No content generated.\"))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38862a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- YouTube to Blog Post Generator ---\n",
      "--- 1. FETCHING TRANSCRIPT ---\n",
      "Transcript fetched successfully. Length: 134190 characters.\n",
      "--- 2. GENERATING BLOG TITLE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR generating title: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "--- An error occurred. Ending execution. ---\n",
      "\n",
      "==================================================\n",
      "Process finished with an error:\n",
      "Failed to generate title: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"--- YouTube to Blog Post Generator ---\")\n",
    "\n",
    "if not url:\n",
    "    print(\"No URL provided. Exiting.\")\n",
    "else:\n",
    "    # Use the existing app and initial_state variables\n",
    "    final_state = app.invoke(initial_state)\n",
    "    \n",
    "    # Print the final output\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    if final_state.get(\"error\"):\n",
    "        print(\"Process finished with an error:\")\n",
    "        print(final_state[\"error\"])\n",
    "    else:\n",
    "        print(\"Final Blog Post:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"# \" + final_state.get(\"title\", \"No Title Generated\"))\n",
    "        print(final_state.get(\"blog_post\", \"No content generated.\"))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68411f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_to_blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
